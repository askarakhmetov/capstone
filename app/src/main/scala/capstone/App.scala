/*
 * This Scala source file was generated by the Gradle 'init' task.
 */
package capstone

import org.apache.spark.SparkConf
import org.apache.spark.SparkContext
import org.apache.spark.SparkContext._
import org.apache.spark.rdd.RDD
import annotation.tailrec
import scala.reflect.ClassTag
import java.sql.Timestamp

object App {

  import org.apache.spark.sql.SparkSession
  import org.apache.spark.sql.functions._

  val spark: SparkSession =
    SparkSession
      .builder()
      .appName("Capstone")
      .master("local")
      .getOrCreate()

  // For implicit conversions like converting RDDs to DataFrames
  import spark.implicits._

  def main(args: Array[String]): Unit = {
    val df = spark.read.options(Map("header" -> "true", "inferSchema" -> "true")).csv("capstone-dataset/mobile_app_clickstream/mobile_app_clickstream_0.csv.gz")
    val df2 = spark.read.options(Map("header" -> "true", "inferSchema" -> "true")).csv("capstone-dataset/user_purchases/user_purchases_0.csv.gz")

    df.createOrReplaceTempView("sdf")
    df2.createOrReplaceTempView("sdf2")

    val query2 = """SELECT sdf2.purchaseId, purchaseTime, billingCost, isConfirmed, tmps.userId as sessionId, campaignId, channelId
                   |    FROM sdf2
                   |    INNER JOIN (select userId, get_json_object(attributes, '$.purchase_id') as purchaseId
                              from sdf order by userId) as tmps
                   |    ON tmps.purchaseId = sdf2.purchaseId
                   |    INNER JOIN (select userId, get_json_object(attributes, '$.campaign_id') as campaignId,
                                            get_json_object(attributes, '$.channel_id') as channelId
                            from sdf
                            where get_json_object(attributes, '$.campaign_id') is not null
                            and get_json_object(attributes, '$.channel_id') is not null
                            order by userId) as tmpss
                   |    ON tmpss.userId = tmps.userId order by sdf2.purchaseId"""

    val query1 = """SELECT sdf2.purchaseId, purchaseTime, billingCost, isConfirmed, userId as sessionId, campaignId, channelId
            |    FROM sdf2 INNER JOIN (select userId,
                                      get_json_object(collect_list(attributes)[0], '$.campaign_id') as campaignId,
                                      get_json_object(collect_list(attributes)[0], '$.channel_id') as channelId,
                                      get_json_object(collect_list(attributes)[1], '$.purchase_id') as purchaseId
                                      from sdf group by userId) as tmps
              ON tmps.purchaseId = sdf2.purchaseId order by sdf2.purchaseId"""

    val projTable1 = spark.sql(query1.stripMargin)
    val projTable2 = spark.sql(query2.stripMargin)

    projTable1.show(5, false)
    projTable2.show(5,false)

    spark.close()
  }

}
